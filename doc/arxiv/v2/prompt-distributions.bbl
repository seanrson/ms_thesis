\begin{thebibliography}{22}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Chen \& Chu(2023)Chen and Chu]{chen2023causal}
Wenqing Chen and Zhixuan Chu.
\newblock Causal inference and natural language processing.
\newblock In \emph{Machine Learning for Causal Inference}, pp.\  189--206.
  Springer, 2023.

\bibitem[Dong et~al.(2023)Dong, Xiong, Goyal, Pan, Diao, Zhang, Shum, and
  Zhang]{dong2023raft}
Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng Zhang,
  Kashun Shum, and Tong Zhang.
\newblock Raft: Reward ranked finetuning for generative foundation model
  alignment.
\newblock \emph{arXiv preprint arXiv:2304.06767}, 2023.

\bibitem[Fan et~al.(2019)Fan, Jernite, Perez, Grangier, Weston, and
  Auli]{eli5_lfqa}
Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and
  Michael Auli.
\newblock {ELI5:} long form question answering.
\newblock In Anna Korhonen, David~R. Traum, and Llu{\'{\i}}s M{\`{a}}rquez
  (eds.), \emph{Proceedings of the 57th Conference of the Association for
  Computational Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2,
  2019, Volume 1: Long Papers}, pp.\  3558--3567. Association for Computational
  Linguistics, 2019.
\newblock \doi{10.18653/v1/p19-1346}.
\newblock URL \url{https://doi.org/10.18653/v1/p19-1346}.

\bibitem[Faraone(2008)]{faraone2008interpreting}
Stephen~V Faraone.
\newblock Interpreting estimates of treatment effects: implications for managed
  care.
\newblock \emph{Pharmacy and Therapeutics}, 33\penalty0 (12):\penalty0 700,
  2008.

\bibitem[Feder et~al.(2022)Feder, Keith, Manzoor, Pryzant, Sridhar,
  Wood-Doughty, Eisenstein, Grimmer, Reichart, Roberts, Stewart, Veitch, and
  Yang]{feder2022causalinferencenaturallanguage}
Amir Feder, Katherine~A. Keith, Emaad Manzoor, Reid Pryzant, Dhanya Sridhar,
  Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart,
  Margaret~E. Roberts, Brandon~M. Stewart, Victor Veitch, and Diyi Yang.
\newblock Causal inference in natural language processing: Estimation,
  prediction, interpretation and beyond, 2022.
\newblock URL \url{https://arxiv.org/abs/2109.00725}.

\bibitem[Grimmer et~al.(2022)Grimmer, Roberts, and Stewart]{grimmer2022text}
Justin Grimmer, Margaret~E Roberts, and Brandon~M Stewart.
\newblock \emph{Text as data: A new framework for machine learning and the
  social sciences}.
\newblock Princeton University Press, 2022.

\bibitem[Gui \& Veitch(2023)Gui and Veitch]{gui2023causalestimationtextdata}
Lin Gui and Victor Veitch.
\newblock Causal estimation for text data with (apparent) overlap violations,
  2023.
\newblock URL \url{https://arxiv.org/abs/2210.00079}.

\bibitem[Hern{\'a}n(2016)]{hernan2016does}
Miguel~A Hern{\'a}n.
\newblock Does water kill? a call for less casual causal inferences.
\newblock \emph{Annals of epidemiology}, 26\penalty0 (10):\penalty0 674--680,
  2016.

\bibitem[Jin et~al.(2022)Jin, Feder, and Zhang]{jin-etal-2022-causalnlp}
Zhijing Jin, Amir Feder, and Kun Zhang.
\newblock {C}ausal{NLP} tutorial: An introduction to causality for natural
  language processing.
\newblock In Samhaa~R. El-Beltagy and Xipeng Qiu (eds.), \emph{Proceedings of
  the 2022 Conference on Empirical Methods in Natural Language Processing:
  Tutorial Abstracts}, pp.\  17--22, Abu Dubai, UAE, December 2022. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.emnlp-tutorials.4}.
\newblock URL \url{https://aclanthology.org/2022.emnlp-tutorials.4}.

\bibitem[Kahneman \& Tversky(2013)Kahneman and Tversky]{kahneman2013prospect}
Daniel Kahneman and Amos Tversky.
\newblock Prospect theory: An analysis of decision under risk.
\newblock In \emph{Handbook of the fundamentals of financial decision making:
  Part I}, pp.\  99--127. World Scientific, 2013.

\bibitem[Lambert et~al.(2024)Lambert, Pyatkin, Morrison, Miranda, Lin, Chandu,
  Dziri, Kumar, Zick, Choi, Smith, and
  Hajishirzi]{lambert2024rewardbenchevaluatingrewardmodels}
Nathan Lambert, Valentina Pyatkin, Jacob Morrison, LJ~Miranda, Bill~Yuchen Lin,
  Khyathi Chandu, Nouha Dziri, Sachin Kumar, Tom Zick, Yejin Choi, Noah~A.
  Smith, and Hannaneh Hajishirzi.
\newblock Rewardbench: Evaluating reward models for language modeling, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.13787}.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and
  Potts]{maas-EtAl:2011:ACL-HLT2011}
Andrew~L. Maas, Raymond~E. Daly, Peter~T. Pham, Dan Huang, Andrew~Y. Ng, and
  Christopher Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies}, pp.\  142--150,
  Portland, Oregon, USA, June 2011. Association for Computational Linguistics.
\newblock URL \url{http://www.aclweb.org/anthology/P11-1015}.

\bibitem[Park et~al.(2024{\natexlab{a}})Park, Jwa, Ren, Kim, and
  Choi]{park2024offsetbias}
Junsoo Park, Seungyeon Jwa, Meiying Ren, Daeyoung Kim, and Sanghyuk Choi.
\newblock Offsetbias: Leveraging debiased data for tuning evaluators,
  2024{\natexlab{a}}.

\bibitem[Park et~al.(2024{\natexlab{b}})Park, Rafailov, Ermon, and
  Finn]{park2024disentanglinglengthqualitydirect}
Ryan Park, Rafael Rafailov, Stefano Ermon, and Chelsea Finn.
\newblock Disentangling length from quality in direct preference optimization,
  2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2403.19159}.

\bibitem[Sanh et~al.(2020)Sanh, Debut, Chaumond, and
  Wolf]{sanh2020distilbertdistilledversionbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and
  lighter, 2020.
\newblock URL \url{https://arxiv.org/abs/1910.01108}.

\bibitem[Saxon et~al.(2024)Saxon, Holtzman, West, Wang, and
  Saphra]{saxon2024benchmarksmicroscopesmodelmetrology}
Michael Saxon, Ari Holtzman, Peter West, William~Yang Wang, and Naomi Saphra.
\newblock Benchmarks as microscopes: A call for model metrology, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.16711}.

\bibitem[Shen et~al.(2023)Shen, Zheng, Zhan, Zhao, Dou, Gui, Zhang, and
  Huang]{shen2023looselipssinkships}
Wei Shen, Rui Zheng, Wenyu Zhan, Jun Zhao, Shihan Dou, Tao Gui, Qi~Zhang, and
  Xuanjing Huang.
\newblock Loose lips sink ships: Mitigating length bias in reinforcement
  learning from human feedback, 2023.
\newblock URL \url{https://arxiv.org/abs/2310.05199}.

\bibitem[Singhal et~al.(2024)Singhal, Goyal, Xu, and
  Durrett]{singhal2024longwaygoinvestigating}
Prasann Singhal, Tanya Goyal, Jiacheng Xu, and Greg Durrett.
\newblock A long way to go: Investigating length correlations in rlhf, 2024.
\newblock URL \url{https://arxiv.org/abs/2310.03716}.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher-etal-2013-recursive}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1631--1642, Seattle, Washington, USA,
  October 2013. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/D13-1170}.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Xiong, Xie, Zhao, and
  Zhang]{ArmoRM}
Haoxiang Wang, Wei Xiong, Tengyang Xie, Han Zhao, and Tong Zhang.
\newblock Interpretable preferences via multi-objective reward modeling and
  mixture-of-experts.
\newblock In \emph{EMNLP}, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Kulikov, Golovneva, Yu, Yuan,
  Dwivedi-Yu, Pang, Fazel-Zarandi, Weston, and
  Li]{wang2024selftaughtevaluators}
Tianlu Wang, Ilia Kulikov, Olga Golovneva, Ping Yu, Weizhe Yuan, Jane
  Dwivedi-Yu, Richard~Yuanzhe Pang, Maryam Fazel-Zarandi, Jason Weston, and
  Xian Li.
\newblock Self-taught evaluators, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2408.02666}.

\bibitem[Wang et~al.(2023)Wang, Dong, Zeng, Adams, Sreedhar, Egert, Delalleau,
  Scowcroft, Kant, Swope, and Kuchaiev]{wang2023helpsteer}
Zhilin Wang, Yi~Dong, Jiaqi Zeng, Virginia Adams, Makesh~Narsimhan Sreedhar,
  Daniel Egert, Olivier Delalleau, Jane~Polak Scowcroft, Neel Kant, Aidan
  Swope, and Oleksii Kuchaiev.
\newblock Helpsteer: Multi-attribute helpfulness dataset for steerlm, 2023.

\end{thebibliography}
