\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{shen2023looselipssinkships,park2024disentanglinglengthqualitydirect,singhal2024longwaygoinvestigating}
\citation{feder2022causalinferencenaturallanguage,grimmer2022text,jin-etal-2022-causalnlp,chen2023causal,gui2023causalestimationtextdata}
\providecommand \oddpage@label [2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\babel@aux{english}{}
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:introduction@cref}{{[section][1][]1}{[1][1][]1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:compare}{{1}{2}{Correlations in our dataset may prevent us from isolating the effect of helpfulness on the reward model. For instance, helpful responses may tend to be longer.\relax }{figure.caption.2}{}}
\newlabel{fig:compare@cref}{{[figure][1][]1}{[1][2][]2}}
\newlabel{sec:setup}{{2}{2}{Setup}{section.2}{}}
\newlabel{sec:setup@cref}{{[section][2][]2}{[1][2][]2}}
\citation{kahneman2013prospect}
\newlabel{tab:rewrites}{{1}{3}{GPT-4o qualitatively does well at rewriting IMDB responses to change sentiment from negative (W = 0) to positive (W = 1). The first example was selected for illustrative purposes, the latter two were randomly selected from the dataset.\relax }{table.caption.4}{}}
\newlabel{tab:rewrites@cref}{{[table][1][]1}{[1][3][]3}}
\citation{hernan2016does}
\newlabel{tab:rewrite_prompts}{{2}{4}{Example rewrite prompts from experiments with sentiment and length as the target attribute. For the ELI5 dataset, some of the responses were phrased as questions, so we instructed the LLM \emph {not} to answer the question and instead rewrite it.\relax }{table.caption.8}{}}
\newlabel{tab:rewrite_prompts@cref}{{[table][2][]2}{[1][4][]4}}
\newlabel{sec:rate}{{3}{4}{RATE: Rewrite-based Attribute Treatment Estimators}{section.3}{}}
\newlabel{sec:rate@cref}{{[section][3][]3}{[1][4][]4}}
\newlabel{tab:formatting_v2}{{3}{5}{Excerpt from rewriting IMDB responses to change length from long $(W = 1)$ to short $(W = 0)$. HTML tags (an off-target attribute) are removed in the rewrite.\relax }{table.caption.10}{}}
\newlabel{tab:formatting_v2@cref}{{[table][3][]3}{[1][4][]5}}
\newlabel{tab:rewrites-rewrites}{{4}{5}{Whether for a rewrite or a rewrite-of-a-rewrite, GPT-4o uses well-formatted text and a slightly formal tone. Here, W is length; samples are drawn from the ELI5 dataset, scored using ArmoRM, and truncated to 100 characters for display. The first was selected for illustrative purposes, the latter two were randomly selected from the dataset.\relax }{table.caption.11}{}}
\newlabel{tab:rewrites-rewrites@cref}{{[table][4][]4}{[1][5][]5}}
\newlabel{alg:rate}{{1}{6}{RATE: Rewrite-based Attribute Treatment Estimators\relax }{algorithm.1}{}}
\newlabel{alg:rate@cref}{{[algorithm][1][]1}{[1][5][]6}}
\newlabel{sec:theory}{{4}{6}{Theoretical Analysis of RATE}{section.4}{}}
\newlabel{sec:theory@cref}{{[section][4][]4}{[1][6][]6}}
\citation{faraone2008interpreting}
\citation{faraone2008interpreting}
\citation{lambert2024rewardbenchevaluatingrewardmodels}
\citation{maas-EtAl:2011:ACL-HLT2011}
\citation{eli5_lfqa}
\citation{wang2023helpsteer}
\citation{dong2023raft}
\citation{park2024offsetbias}
\newlabel{thmt@@mainthm@data}{{\def \theequation {4.\@arabic {\c@equation }}\def \theHequation {(restate \theHthmt@dummyctr )4.\@arabic {\c@equation }}\setcounter {equation}{0}}{7}{Unbiasedness and Consistency of RATE}{Item.9}{}}
\newlabel{thmt@@mainthm@data@cref}{{[section][4][]4}{[1][7][]7}}
\newlabel{thmt@@mainthm}{{1}{7}{Unbiasedness and Consistency}{theorem.1}{}}
\newlabel{thmt@@mainthm@cref}{{[theorem][1][]1}{[1][7][]7}}
\newlabel{thm:mainthm}{{1}{7}{Unbiasedness and Consistency}{theorem.1}{}}
\newlabel{thm:mainthm@cref}{{[theorem][1][]1}{[1][7][]7}}
\newlabel{sec:experiments}{{5}{7}{Experiments}{section.5}{}}
\newlabel{sec:experiments@cref}{{[section][5][]5}{[1][7][]7}}
\citation{socher-etal-2013-recursive,sanh2020distilbertdistilledversionbert}
\citation{ArmoRM}
\newlabel{fig:naive}{{2}{8}{An attribute's reported effect on a reward model differs substantially between the naive (non-causal) estimate compared to the RATE (causal) estimate. The naive estimator overstates the length bias of FsfairX-LLaMA3-RM-v0.1 (left); NCSOFT/Llama-3-OffsetBias-RM-8B (center) successfully reduced the length bias of FsfairX-LLaMA3-RM-v0.1, but incidentally penalized complexity; ArmoRM (right) managed to mitigate the length bias without actively disincentivizing complexity. Effect sizes are reported as standardized mean differences, using Cohen's \emph {d} to compare average treatment effects that are normalized \citep {faraone2008interpreting}. Bars represent a 95\% confidence interval.\relax }{figure.caption.15}{}}
\newlabel{fig:naive@cref}{{[figure][2][]2}{[1][7][]8}}
\newlabel{sec:synthetic}{{5}{8}{Synthetic Experiments}{section*.17}{}}
\newlabel{sec:synthetic@cref}{{[section][5][]5}{[1][7][]8}}
\newlabel{fig:synthetic_combo}{{3}{9}{The RATE estimator is robust to distributional shift and better approximates the (assumed) near-zero ATE of length on DistilBERT. Sample size = 9374 for all levels of correlation for the IMDB experiment, and 5148 for the HelpSteer experiment. 95\% confidence intervals are shown.\relax }{figure.caption.18}{}}
\newlabel{fig:synthetic_combo@cref}{{[figure][3][]3}{[1][8][]9}}
\newlabel{tab:strange-syntax}{{5}{9}{For some text, our target attribute (W = Sentiment) is not well-defined. Rewrites add strange syntax: \enquote {annoyingly the same size} and \enquote {frustratingly square}. Data from the HH-RLHF dataset.\relax }{table.caption.20}{}}
\newlabel{tab:strange-syntax@cref}{{[table][5][]5}{[1][8][]9}}
\newlabel{fig:kde}{{4}{10}{The distributions of reward scores for original responses and rewrites of rewrites differ. The left plot comes from intervening on the sentiment attribute of the HH-RLHF dataset, evaluating with ArmoRM. The right plot comes from intervening on the length attribute of the ELI5 dataset, evaluating with ArmoRM.\relax }{figure.caption.21}{}}
\newlabel{fig:kde@cref}{{[figure][4][]4}{[1][9][]10}}
\newlabel{fig:bias}{{5}{10}{Treatment effect estimates differ substantially between the single rewrite and double rewrite methods. Bars represent a 95\% confidence interval.\relax }{figure.caption.22}{}}
\newlabel{fig:bias@cref}{{[figure][5][]5}{[1][9][]10}}
\newlabel{sec:discussion}{{6}{10}{Discussion}{section.6}{}}
\newlabel{sec:discussion@cref}{{[section][6][]6}{[1][9][]10}}
\citation{saxon2024benchmarksmicroscopesmodelmetrology}
\citation{wang2024selftaughtevaluators}
\bibdata{bibs/interpretability.bib,bibs/alignment.bib,bibs/counterfactual_samples.bib,bibs/treatment_effects.bib,bibs/length.bib,bibs/misc.bib}
\bibcite{chen2023causal}{{1}{2023}{{Chen \& Chu}}{{Chen and Chu}}}
\bibcite{dong2023raft}{{2}{2023}{{Dong et~al.}}{{Dong, Xiong, Goyal, Pan, Diao, Zhang, Shum, and Zhang}}}
\bibcite{eli5_lfqa}{{3}{2019}{{Fan et~al.}}{{Fan, Jernite, Perez, Grangier, Weston, and Auli}}}
\bibcite{faraone2008interpreting}{{4}{2008}{{Faraone}}{{}}}
\bibcite{feder2022causalinferencenaturallanguage}{{5}{2022}{{Feder et~al.}}{{Feder, Keith, Manzoor, Pryzant, Sridhar, Wood-Doughty, Eisenstein, Grimmer, Reichart, Roberts, Stewart, Veitch, and Yang}}}
\bibcite{grimmer2022text}{{6}{2022}{{Grimmer et~al.}}{{Grimmer, Roberts, and Stewart}}}
\bibcite{gui2023causalestimationtextdata}{{7}{2023}{{Gui \& Veitch}}{{Gui and Veitch}}}
\bibcite{hernan2016does}{{8}{2016}{{Hern{\'a}n}}{{}}}
\bibcite{jin-etal-2022-causalnlp}{{9}{2022}{{Jin et~al.}}{{Jin, Feder, and Zhang}}}
\bibcite{kahneman2013prospect}{{10}{2013}{{Kahneman \& Tversky}}{{Kahneman and Tversky}}}
\bibcite{lambert2024rewardbenchevaluatingrewardmodels}{{11}{2024}{{Lambert et~al.}}{{Lambert, Pyatkin, Morrison, Miranda, Lin, Chandu, Dziri, Kumar, Zick, Choi, Smith, and Hajishirzi}}}
\bibcite{maas-EtAl:2011:ACL-HLT2011}{{12}{2011}{{Maas et~al.}}{{Maas, Daly, Pham, Huang, Ng, and Potts}}}
\bibcite{park2024offsetbias}{{13}{2024{}}{{Park et~al.}}{{Park, Jwa, Ren, Kim, and Choi}}}
\bibcite{park2024disentanglinglengthqualitydirect}{{14}{2024{}}{{Park et~al.}}{{Park, Rafailov, Ermon, and Finn}}}
\bibcite{sanh2020distilbertdistilledversionbert}{{15}{2020}{{Sanh et~al.}}{{Sanh, Debut, Chaumond, and Wolf}}}
\bibcite{saxon2024benchmarksmicroscopesmodelmetrology}{{16}{2024}{{Saxon et~al.}}{{Saxon, Holtzman, West, Wang, and Saphra}}}
\bibcite{shen2023looselipssinkships}{{17}{2023}{{Shen et~al.}}{{Shen, Zheng, Zhan, Zhao, Dou, Gui, Zhang, and Huang}}}
\bibcite{singhal2024longwaygoinvestigating}{{18}{2024}{{Singhal et~al.}}{{Singhal, Goyal, Xu, and Durrett}}}
\bibcite{socher-etal-2013-recursive}{{19}{2013}{{Socher et~al.}}{{Socher, Perelygin, Wu, Chuang, Manning, Ng, and Potts}}}
\bibcite{ArmoRM}{{20}{2024{}}{{Wang et~al.}}{{Wang, Xiong, Xie, Zhao, and Zhang}}}
\bibcite{wang2024selftaughtevaluators}{{21}{2024{}}{{Wang et~al.}}{{Wang, Kulikov, Golovneva, Yu, Yuan, Dwivedi-Yu, Pang, Fazel-Zarandi, Weston, and Li}}}
\bibcite{wang2023helpsteer}{{22}{2023}{{Wang et~al.}}{{Wang, Dong, Zeng, Adams, Sreedhar, Egert, Delalleau, Scowcroft, Kant, Swope, and Kuchaiev}}}
\bibstyle{bibs/iclr2025_conference}
\newlabel{sec:proofs}{{A}{13}{Proofs}{appendix.A}{}}
\newlabel{sec:proofs@cref}{{[appendix][1][2147483647]A}{[1][13][]13}}
\gdef \@abspage@last{14}
